{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import pickle\n",
    "import collections\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD=0\n",
    "UNK=1\n",
    "SOS=2\n",
    "\n",
    "device_kind=\"cuda:{}\".format(cuda_number) if torch.cuda.is_available() else \"cpu\"\n",
    "device=torch.device(device_kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idmaker(sentences,vocab_size):\n",
    "    words=collections.defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        for w in sentence:\n",
    "            words[w]+=1\n",
    "            \n",
    "    words=sorted(words.items(),key=lambda x:-x[1])\n",
    "    word2id={w:i for i,(w,count) in enumerate(words[0:vocab_size],5) if count>=0}\n",
    "    word2id[\"<PAD>\"]=0\n",
    "    word2id[\"<UNK>\"]=1\n",
    "    word2id[\"<SOS>\"]=2\n",
    "    word2id[\"<EOS>\"]=3\n",
    "    word2id[\"<SEP>\"]=4\n",
    "\n",
    "    id2word={i:w for w,i in list(word2id.items())}\n",
    "    \n",
    "    return word2id,id2word\n",
    "\n",
    "def process_word2id(sentences,word2id_dict,tgt):\n",
    "    sentences=[[word2id_dict[w] if w in word2id_dict else word2id_dict[\"<UNK>\"]  for w in sentence]  for sentence in sentences]\n",
    "    if tgt:\n",
    "        sentences=[[word2id_dict[\"<SOS>\"]] + sentence + [word2id_dict[\"<EOS>\"]] for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(src_path,tgt_path,train):\n",
    "    src=[]\n",
    "    tgt=[]\n",
    "    with open(src_path)as f:\n",
    "        for line in f:\n",
    "            src.append(line.strip().split())\n",
    "    with open(tgt_path)as f:\n",
    "        for line in f:\n",
    "            tgt.append(line.strip().split())\n",
    "            \n",
    "    src=[sentence for sentence in src if len(sentence)<=max_src_size]\n",
    "    tgt=[sentence for sentence in tgt if len(sentence)<=max_tgt_size]\n",
    "            \n",
    "    src_word2id,src_id2word=word2idmaker(src,src_vocab_size)\n",
    "    src_id=process_word2id(src,src_word2id,tgt=False)\n",
    "\n",
    "    tgt_word2id,tgt_id2word=word2idmaker(tgt,tgt_vocab_size)\n",
    "    tgt_id=process_word2id(tgt,tgt_word2id,tgt=True)\n",
    "            \n",
    "    data={}\n",
    "    data[\"src_id\"]=src_id\n",
    "    data[\"tgt_id\"]=tgt_id\n",
    "    if train==True:\n",
    "        data[\"src_id2word\"]=src_id2word\n",
    "        data[\"tgt_id2word\"]=tgt_id2word\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchmaker(data_size,batch_size,shuffle=True):\n",
    "    data=list(range(data_size))\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "    batches=[]\n",
    "    batch=[]\n",
    "    for i in range(data_size):\n",
    "        batch.append(data[i])\n",
    "        if len(batch)==batch_size:\n",
    "            batches.append(batch)\n",
    "            batch=[]\n",
    "    if len(batch)>0:\n",
    "        batches.append(batch)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vec(sentences):\n",
    "    maxsize=max([len(sentence) for sentence in sentences])\n",
    "    sentences=[sentence+[0]*(maxsize-len(sentence)) for sentence in sentences]  \n",
    "    return torch.tensor(sentences).to(device)\n",
    "    #return torch.from_numpy(np.array(sentences_cp,dtype=\"long\")).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_handler(data,train):\n",
    "    sources=data[\"src_id\"]\n",
    "    targets=data[\"tgt_id\"]\n",
    "    #t_id2word=data[\"t_id2word\"]\n",
    "    data_size=len(sources)\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    batches=batchmaker(data_size,batch_size,train)\n",
    "    predict_rate=0\n",
    "    loss_sum=0\n",
    "    for i_batch,batch in enumerate(batches):\n",
    "        input_words=make_vec([sources[i] for i in batch])\n",
    "        output_words=make_vec([targets[i] for i in batch])#(batch,seq_len)\n",
    "        print(input_words.size())\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "        predict,_=model(input_words,output_words,train)#(batch,seq_len,vocab_size)\n",
    "        #trainの場合はパラメータの更新を行う\n",
    "        if train==True:\n",
    "            loss=loss_calc(predict,output_words[:,1:])#batch*seq_lenをして内部で計算\n",
    "            #loss.backward()\n",
    "            #optimizer.step()\n",
    "            loss_sum+=loss.data\n",
    "        else:\n",
    "            predict_rate+=predict_calc(predict,output_words[:,1:])\n",
    "            predict,target=predict_sentence(args,predict,output_words[:,1:],t_id2word)#(batch,seq_len)\n",
    "\n",
    "    #epochの記録\n",
    "    #if train:\n",
    "    #    logger(args,\"epoch:{}\\ttime:{}\\tloss:{}\".format(epoch,time.time()-start,loss_sum/data_size))\n",
    "\n",
    "    else:\n",
    "        predict_rate=predict_rate/data_size\n",
    "        logger(args,\"predict_rate:{}\".format(predict_rate))\n",
    "\n",
    "        #テストデータにおいて、predict_rateが上回った時のみモデルを保存\n",
    "        if data_kind==\"train\" and args.high_score<predict_rate:\n",
    "            args.high_score=predict_rate\n",
    "            args.high_epoch=epoch\n",
    "            torch.save(model.state_dict(), \"model_data/model.pth\"\\\n",
    "                        .format(args.start_time,round(predict_rate,3),epoch))\n",
    "            logger(args,\"save model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder=Encoder()\n",
    "        self.decoder=Decoder()\n",
    "\n",
    "    def forward(self, input_words,output_words,train=True):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_words)#(batch,seq_len,hidden_size*2)\n",
    "        output=self.decoder(encoder_outputs,encoder_hidden,output_words,train)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.word_embed=nn.Embedding(src_vocab_size, embed_size,padding_idx=PAD)\n",
    "        self.rnn=nn.GRU(embed_size,hidden_size,num_layers=layer_size,bidirectional=True,dropout=dropout_rate,batch_first=True)\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self,input_words):#input:(batch,seq_len)\n",
    "        embed = self.word_embed(input_words)#(batch,seq_len,embed_size)\n",
    "        output, hidden=self.rnn(embed) #(batch,seq_len,hidden_size*direction),(direction*layer_size,batch,hidden_size)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.word_embed=nn.Embedding(tgt_vocab_size,embed_size,padding_idx=PAD)\n",
    "        self.rnn=nn.GRU(embed_size,hidden_size,num_layers=layer_size,bidirectional=False,dropout=dropout_rate,batch_first=True)\n",
    "        self.attention=Attention()\n",
    "        self.attention_wight=nn.Linear(hidden_size*3,hidden_size*3)\n",
    "        self.out=nn.Linear(hidden_size*3,tgt_vocab_size)\n",
    "        self.dropout=nn.Dropout(dropout_rate)\n",
    "        self.activate=nn.Tanh()\n",
    "        #self.out=nn.Linear(self.hidden_size*1,self.vocab_size)\n",
    "\n",
    "    #decoderでのタイムステップ（単語ごと）の処理\n",
    "    #input:(batch,1)\n",
    "    #encoder_output:(batch,seq_len,hidden_size*direction)\n",
    "    def decode_step(self,decoder_input,decoder_hidden,encoder_output):\n",
    "        decoder_input=torch.unsqueeze(decoder_input,1)#(batch,1)\n",
    "        embed=self.word_embed(decoder_input)#(batch,1,embed_size)\n",
    "        embed=self.dropout(embed)\n",
    "\n",
    "\n",
    "        output,decoder_hidden=self.rnn(embed,decoder_hidden.contiguous())#(batch,1,hidden_size),(2,batch,hidden_size)\n",
    "        #output=self.dropout(output)\n",
    "        output=torch.squeeze(output,1)#(batch,hidden_size)\n",
    "\n",
    "        use_attention=True\n",
    "        #attentionの計算\n",
    "        if use_attention:\n",
    "            #encoderの出力と合わせてアテンションを計算\n",
    "            attention_output,attention_result=self.attention(output,encoder_output)#(batch,hidden_size*2)\n",
    "            output=self.attention_wight(torch.cat((output,attention_output),dim=-1))#(batch,hidden_size*3)\n",
    "            output=self.activate(output)\n",
    "            output=self.dropout(output)\n",
    "\n",
    "        #単語辞書のサイズに変換する\n",
    "        output=self.out(output)#(batch,vocab_size)\n",
    "\n",
    "        #outputの中で最大値（実際に出力する単語）を返す\n",
    "        predict=torch.argmax(output,dim=-1) #(batch)\n",
    "\n",
    "        return output,decoder_hidden,predict,attention_result\n",
    "\n",
    "    #encoder_output:(batch,seq_len,hidden_size*direction)\n",
    "    #encoder_hidden:(direction*layer_size,batch,hidden_size)\n",
    "    #output_words:(batch,output_seq_len)\n",
    "    def forward(self,encoder_output,encoder_hidden,output_words,train=True):\n",
    "        print(output_words.size())\n",
    "        batch_size=output_words.size(0)\n",
    "        output_seq_len=output_words.size(1)-1\n",
    "        src_seq_len=encoder_output.size(1)\n",
    "\n",
    "        #初期隠れベクトル、batch_first=Trueでも(1,batch,hidden_size)の順番、正直無くても良い\n",
    "        encoder_hidden=encoder_hidden.view(2,layer_size,batch_size,hidden_size)\n",
    "        decoder_hidden=torch.add(encoder_hidden[0],encoder_hidden[1])#(2,layer_size,batch,hidden_size)\n",
    "\n",
    "        source = output_words[:, :-1]\n",
    "        target = output_words[:, 1:]\n",
    "\n",
    "\n",
    "        output_maxlen=output_seq_len\n",
    "        teacher_forcing_ratio=1\n",
    "\n",
    "        #decoderからの出力結果\n",
    "        outputs=torch.from_numpy(np.zeros((output_seq_len,batch_size,tgt_vocab_size))).to(device)\n",
    "        predict=torch.from_numpy(np.array([SOS]*batch_size,dtype=\"long\")).to(device) #(batch_size)\n",
    "        attention_result=torch.zeros(output_seq_len,src_seq_len)\n",
    "\n",
    "        for i in range(output_maxlen):\n",
    "            #使用する入力。\n",
    "            print(i)\n",
    "            current_input=source[:,i] if random.random()<teacher_forcing_ratio else predict.view(-1)#(batch)\n",
    "            output,decoder_hidden,predict,result=self.decode_step(current_input,decoder_hidden,encoder_output)#(batch,vocab_size),(batch)\n",
    "            outputs[i]=output#outputsにdecoderの各ステップから出力されたベクトルを入力\n",
    "            if batch_size==1:\n",
    "                attention_result[i]=result\n",
    "\n",
    "        outputs=torch.transpose(outputs,0,1)#(batch,seq_len,vocab_size)\n",
    "        return outputs,attention_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.W=nn.Linear(hidden_size,hidden_size*2)\n",
    "        self.attention_wight=nn.Linear(hidden_size,hidden_size*2)\n",
    "\n",
    "\n",
    "    #input*W*encoder_outputでscoreを計算(general)\n",
    "    #decoder_hidden:(batch,hidden_size)\n",
    "    #encoder_output:(batch,seq_len,hidden_size*2)\n",
    "    #return:(batch,hidden_size*2)\n",
    "    def forward(self,decoder_hidden,encoder_output):\n",
    "        decoder_hidden=torch.unsqueeze(decoder_hidden,dim=1)#(batch,1,hidden_size)\n",
    "        encoder_output_transpose=torch.transpose(encoder_output,1,2)#(batch,hidden_size*2,seq_len)\n",
    "\n",
    "        output=self.W(decoder_hidden)#(batch,1,hidden_size*2)\n",
    "        output=torch.bmm(output,encoder_output_transpose)#(batch,1,seq_len)\n",
    "        output=F.softmax(output,dim=-1)#(batch,1,seq_len)\n",
    "        attention_result=output#(batch,1,seq_len)\n",
    "\n",
    "        output=torch.bmm(output,encoder_output)#(batch,1,hidden_size*2)\n",
    "        output=torch.squeeze(output,dim=1)#(batch,hidden_size*2)\n",
    "        return output,attention_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(predict,target):\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "    batch=predict.size(0)\n",
    "    seq_len=predict.size(1)\n",
    "    predict=predict.contiguous().view(batch*seq_len,-1)#(batch*seq_len,vocab_size)\n",
    "    target=target.contiguous().view(-1)#(batch*seq_len)\n",
    "    loss=criterion(predict,target)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_number=0\n",
    "epoch_num=5\n",
    "batch_size=32\n",
    "embed_size=300\n",
    "dropout_rate=0.3\n",
    "hidden_size=256\n",
    "layer_size=2\n",
    "max_src_size=100\n",
    "max_tgt_size=100\n",
    "src_vocab_size=30000\n",
    "tgt_vocab_size=30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data_loader(src_path=\"data/kyoto-train.ja\",tgt_path=\"data/kyoto-train.en\",train=True)\n",
    "test_data=data_loader(src_path=\"data/kyoto-dev.ja\",tgt_path=\"data/kyoto-dev.en\",train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 51])\n",
      "torch.Size([32, 87])\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-6f282a1c70d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-111-ae6580ba9851>\u001b[0m in \u001b[0;36mmodel_handler\u001b[0;34m(data, train)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(batch,seq_len,vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m#trainの場合はパラメータの更新を行う\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-0bf51fa8b1a7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_words, output_words, train)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(batch,seq_len,hidden_size*2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-7e93d7ffc92c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_output, encoder_hidden, output_words, train)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mcurrent_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mteacher_forcing_ratio\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(batch,vocab_size),(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;31m#outputsにdecoderの各ステップから出力されたベクトルを入力\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-7e93d7ffc92c>\u001b[0m in \u001b[0;36mdecode_step\u001b[0;34m(self, decoder_input, decoder_hidden, encoder_output)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m#単語辞書のサイズに変換する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#(batch,vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#outputの中で最大値（実際に出力する単語）を返す\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Seq2Seq()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(0,epoch_num):\n",
    "    model_handler(train_data,train=True)\n",
    "    model_handler(test_data,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
